{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Proba-V Dataset\n",
    "![proba_v_dataset](media/proba_v_dataset.jpg \"Logo Title Text 1\")\n",
    "\n",
    "The following notebook provides a very flexible pipeline for processing the Proba-V Dataset. We have already split the original dataset in train validation and test. The test set is the original one of the ESA Proba-V challenge without ground-truths. The validation set is composed of all the scenes we used to evaluate our network and all significant solutions presented in literature at the time of writing.\n",
    "\n",
    "**NB**: with the setting \"train_full=True\" our validation split will be ignored, and you will have a pre-processed dataset with all scenes available in the dataset. It is useful if you want to compete in the [PROBA-V Super Resolution post mortem Challenge](https://kelvins.esa.int/proba-v-super-resolution-post-mortem/home/)\n",
    "\n",
    "**The notebook is divided in**:\n",
    "- 1.0 [Dataset Loading](#section_ID)\n",
    "- 2.0 [Dataset pre-processing](#preprocessing)\n",
    "    - 2.1 Register dataset\n",
    "    - 2.2 Select the best T LR images\n",
    "    - 2.3 Pre-augment dataset (temporal permutation)\n",
    "- 3.0 [Visualize the Pre-Processed Datataset](#visualize)\n",
    "- 4.0 [Save dataset](#save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:31:53.362106Z",
     "start_time": "2020-04-07T12:31:53.156260Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:31:54.183410Z",
     "start_time": "2020-04-07T12:31:53.907155Z"
    }
   },
   "outputs": [],
   "source": [
    "# import utils and basic libraries\n",
    "from utils.preprocessing import load_dataset,select_T_images,register_dataset,augment_dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:31:54.654503Z",
     "start_time": "2020-04-07T12:31:54.640356Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------\n",
    "# Settings\n",
    "#-------------\n",
    "T = 9                                # number of temporal dimension\n",
    "n_augment = 7                        # number of temporal permutations to augment the dataset\n",
    "dataset_dir = 'probav_data'          # input dir (train val and test splitted)\n",
    "dataset_output_dir = 'dataset'       # output dir\n",
    "threshold_clean = 0.85               # percentage of clear pixel\n",
    "train_full = False                   # train without a validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>\n",
    "# 1.0 Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:32:04.363750Z",
     "start_time": "2020-04-07T12:31:55.707527Z"
    }
   },
   "outputs": [],
   "source": [
    "# train loading\n",
    "X_RED_train, X_RED_train_masks, y_RED_train, y_RED_train_masks = load_dataset(base_dir=dataset_dir, \n",
    "                                                                              part=\"train\", band=\"RED\")\n",
    "X_NIR_train, X_NIR_train_masks, y_NIR_train, y_NIR_train_masks = load_dataset(base_dir=dataset_dir,\n",
    "                                                                              part=\"train\", band=\"NIR\")\n",
    "\n",
    "print(f\"Train RED scenes: {len(X_RED_train)} | Train RED y shape: {y_RED_train.shape}\")\n",
    "print(f\"Train NIR scenes: {len(X_NIR_train)} | Train NIR y shape: {y_NIR_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:18:21.976362Z",
     "start_time": "2020-04-07T13:18:19.093732Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation loading\n",
    "X_RED_val, X_RED_val_masks, y_RED_val, y_RED_val_masks = load_dataset(base_dir=dataset_dir,\n",
    "                                                                      part=\"val\", band=\"RED\")\n",
    "X_NIR_val, X_NIR_val_masks, y_NIR_val, y_NIR_val_masks = load_dataset(base_dir=dataset_dir,\n",
    "                                                                      part=\"val\", band=\"NIR\")\n",
    "\n",
    "print(f\"Val RED scenes: {len(X_RED_val)} | Val RED y shape: {y_RED_val.shape}\")\n",
    "print(f\"Val NIR scenes: {len(X_NIR_val)} | Val NIR y shape: {y_NIR_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:32:17.317664Z",
     "start_time": "2020-04-07T12:32:14.829993Z"
    }
   },
   "outputs": [],
   "source": [
    "# test loading\n",
    "X_RED_test, X_RED_test_masks = load_dataset(base_dir=dataset_dir,part=\"test\",band=\"RED\")\n",
    "X_NIR_test, X_NIR_test_masks = load_dataset(base_dir=dataset_dir,part=\"test\",band=\"NIR\")\n",
    "\n",
    "print(f\"Test RED scenes: {len(X_RED_test)}\")\n",
    "print(f\"Test NIR scenes: {len(X_NIR_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "# 2.0 Dataset Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:36:46.137079Z",
     "start_time": "2020-04-07T12:32:20.312183Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train registration\n",
    "X_RED_train, X_RED_train_masks = register_dataset(X_RED_train, X_RED_train_masks)\n",
    "X_NIR_train, X_NIR_train_masks = register_dataset(X_NIR_train, X_NIR_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:20:15.272789Z",
     "start_time": "2020-04-07T13:18:23.716191Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation registration\n",
    "X_RED_val, X_RED_val_masks = register_dataset(X_RED_val, X_RED_val_masks)\n",
    "X_NIR_val, X_NIR_val_masks = register_dataset(X_NIR_val, X_NIR_val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:40:20.789623Z",
     "start_time": "2020-04-07T12:38:47.233346Z"
    }
   },
   "outputs": [],
   "source": [
    "# test registration\n",
    "X_RED_test, X_RED_test_masks = register_dataset(X_RED_test, X_RED_test_masks)\n",
    "X_NIR_test, X_NIR_test_masks = register_dataset(X_NIR_test, X_NIR_test_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Select the best T LR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:17:06.162057Z",
     "start_time": "2020-04-07T13:17:04.345967Z"
    }
   },
   "outputs": [],
   "source": [
    "# select T train\n",
    "X_RED_train, remove_indexes_RED_train = select_T_images(X_RED_train, X_RED_train_masks,\n",
    "                                                                     T, thr=threshold_clean)\n",
    "X_NIR_train, remove_indexes_NIR_train = select_T_images(X_NIR_train, X_NIR_train_masks, \n",
    "                                                                     T, thr=threshold_clean)\n",
    "\n",
    "print(f\"Train RED shape: {X_RED_train.shape}\")\n",
    "print(f\"Train NIR shape: {X_NIR_train.shape}\")\n",
    "print(f\"Train indexes removed RED: {remove_indexes_RED_train}\")\n",
    "print(f\"Train indexes removed NIR: {remove_indexes_NIR_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:47:57.048483Z",
     "start_time": "2020-04-07T12:47:56.984921Z"
    }
   },
   "outputs": [],
   "source": [
    "# delete awful scenes training\n",
    "y_RED_train = np.delete(y_RED_train, remove_indexes_RED_train, axis=0)\n",
    "y_RED_train_masks = np.delete(y_RED_train_masks, remove_indexes_RED_train, axis=0)\n",
    "y_NIR_train = np.delete(y_NIR_train, remove_indexes_NIR_train, axis=0)\n",
    "y_NIR_train_masks = np.delete(y_NIR_train_masks, remove_indexes_NIR_train, axis=0)\n",
    "\n",
    "print(f\"Train RED y shape: {y_RED_train.shape}\")\n",
    "print(f\"Train NIR y shape: {y_NIR_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:20:18.242468Z",
     "start_time": "2020-04-07T13:20:17.754980Z"
    }
   },
   "outputs": [],
   "source": [
    "# select T validation\n",
    "X_RED_val, remove_indexes_RED_val = select_T_images(X_RED_val, X_RED_val_masks, \n",
    "                                                                 T, thr=threshold_clean)\n",
    "X_NIR_val, remove_indexes_NIR_val = select_T_images(X_NIR_val, X_NIR_val_masks,\n",
    "                                                                 T, thr=threshold_clean)\n",
    "\n",
    "print(f\"Val RED shape: {X_RED_train.shape}\")\n",
    "print(f\"Val NIR shape: {X_NIR_train.shape}\")\n",
    "print(f\"Val indexes removed RED: {remove_indexes_RED_val}\")\n",
    "print(f\"Val indexes removed NIR: {remove_indexes_NIR_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:20:19.495859Z",
     "start_time": "2020-04-07T13:20:19.471850Z"
    }
   },
   "outputs": [],
   "source": [
    "# delete awful scenes validation\n",
    "y_RED_val = np.delete(y_RED_val, remove_indexes_RED_val, axis=0)\n",
    "y_RED_val_masks = np.delete(y_RED_val_masks, remove_indexes_RED_val, axis=0)\n",
    "y_NIR_val = np.delete(y_NIR_val, remove_indexes_NIR_val, axis=0)\n",
    "y_NIR_val_masks = np.delete(y_NIR_val_masks, remove_indexes_NIR_val, axis=0)\n",
    "\n",
    "print(f\"Val RED y shape: {y_RED_val.shape}\")\n",
    "print(f\"Val NIR y shape: {y_NIR_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:21:32.084545Z",
     "start_time": "2020-04-07T13:21:31.800912Z"
    }
   },
   "outputs": [],
   "source": [
    "# select T test\n",
    "X_RED_test, _ = select_T_images(X_RED_test, X_RED_test_masks,\n",
    "                                                  T, thr=threshold_clean, remove_bad=False) # we can't remove scenes from testing dataset\n",
    "X_NIR_test, _ = select_T_images(X_NIR_test, X_NIR_test_masks,\n",
    "                                                  T, thr=threshold_clean, remove_bad=False) # we can only pick the best T\n",
    "print(f\"Test RED shape: {X_RED_test.shape}\")\n",
    "print(f\"Test NIR shape: {X_NIR_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Pre-augment dataset (temporal permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_full:\n",
    "    X_RED_train = np.concatenate((X_RED_train, X_RED_val))\n",
    "    X_NIR_train = np.concatenate((X_NIR_train, X_NIR_val))\n",
    "    \n",
    "    y_RED_train = np.concatenate((y_RED_train, y_RED_val))\n",
    "    y_NIR_train = np.concatenate((y_NIR_train, y_NIR_val))\n",
    "    \n",
    "    y_RED_train_masks = np.concatenate((y_RED_train_masks, y_RED_val_masks))\n",
    "    y_NIR_train_masks = np.concatenate((y_NIR_train_masks, y_NIR_val_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training dataset only\n",
    "X_RED_train, y_RED_train, y_RED_train_masks = augment_dataset(X_RED_train, y_RED_train,\n",
    "                                                              y_RED_train_masks, n_augment=n_augment)\n",
    "X_NIR_train, y_NIR_train, y_NIR_train_masks = augment_dataset(X_NIR_train, y_NIR_train,\n",
    "                                                              y_NIR_train_masks, n_augment=n_augment)\n",
    "\n",
    "print(f\"Train RED X shape: {X_RED_train.shape} | Train RED y shape: {y_RED_train.shape}\")\n",
    "print(f\"Train NIR X shape: {X_NIR_train.shape} | Train NIR y shape: {y_NIR_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualize\"></a>\n",
    "# 3.0 Visualize the Pre-Processed Datataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------\n",
    "# Settings\n",
    "#-------------\n",
    "index = 30\n",
    "band = 'NIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:26:33.546313Z",
     "start_time": "2020-04-07T13:26:33.171755Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, T, figsize=(20,5))\n",
    "\n",
    "if band == \"NIR\":\n",
    "    for i in range(T):\n",
    "        ax[0,i].imshow(X_NIR_train[index][...,i], cmap = 'gray')\n",
    "        ax[0,i].axis('off')\n",
    "        ax[1,i].imshow(X_NIR_train_masks[index][...,i], cmap = 'gray')\n",
    "        ax[1,i].axis('off')\n",
    "else:\n",
    "    for i in range(T):\n",
    "        ax[0,i].imshow(X_RED_train[index][...,i], cmap = 'gray')\n",
    "        ax[0,i].axis('off')\n",
    "        ax[1,i].imshow(X_RED_train_masks[index][...,i], cmap = 'gray')\n",
    "        ax[1,i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "# 4.0 Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:52:20.085830Z",
     "start_time": "2020-04-07T13:52:19.980337Z"
    }
   },
   "outputs": [],
   "source": [
    "# save training\n",
    "np.save(os.path.join(dataset_output_dir, 'X_RED_train.npy'), X_RED_train)\n",
    "np.save(os.path.join(dataset_output_dir, 'X_NIR_train.npy'), X_NIR_train)\n",
    "\n",
    "np.save(os.path.join(dataset_output_dir, 'y_RED_train.npy'), y_RED_train)\n",
    "np.save(os.path.join(dataset_output_dir, 'y_NIR_train.npy'), y_NIR_train)\n",
    "\n",
    "np.save(os.path.join(dataset_output_dir, 'y_RED_train_masks.npy'), y_RED_train_masks)\n",
    "np.save(os.path.join(dataset_output_dir, 'y_NIR_train_masks.npy'), y_NIR_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:52:20.695395Z",
     "start_time": "2020-04-07T13:52:20.584799Z"
    }
   },
   "outputs": [],
   "source": [
    "# save validation\n",
    "if not train_full:\n",
    "    np.save(os.path.join(dataset_output_dir, 'X_RED_val.npy'), X_RED_val)\n",
    "    np.save(os.path.join(dataset_output_dir, 'X_NIR_val.npy'), X_NIR_val)\n",
    "\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_RED_val.npy'), y_RED_val)\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_NIR_val.npy'), y_NIR_val)\n",
    "\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_RED_val_masks.npy'), y_RED_val_masks)\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_NIR_val_masks.npy'), y_NIR_val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:52:21.208364Z",
     "start_time": "2020-04-07T13:52:21.119969Z"
    }
   },
   "outputs": [],
   "source": [
    "# save test\n",
    "np.save(os.path.join(dataset_output_dir, 'X_RED_test.npy'), X_RED_test)\n",
    "np.save(os.path.join(dataset_output_dir, 'X_NIR_test.npy'), X_NIR_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
